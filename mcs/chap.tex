\chapter{Échantillonnage}
\label{chap:mcs}                   % étiquette pour renvois (à compléter!)

Idée: si on possède une distribution sur les phrases, on souhaiterait savoir
quelle est la performance qui lui est associée (processus de génération
stochastique seulement).

Il serait alors possible de bâtir un système qui apprend à prédire de bonnes
distributions sur les phrases en maximisant directement la performance
reliée à une distribution.

Concrètement, si on souhaite approximer la performance d'une distribution $\pi$
jumelée à un processus de génération de résumé $\phi$, on cherche donc à approximer,
pour un document et son résumé cible ($d, \hat{s}$),

\begin{equation}
    f = \underset{{s \sim \phi(\pi(d))}}{\mathbb{E}} \,\left[R(s, \hat{s})\right],
\end{equation}



Cette fonction ne peut pas être calculée analytiquement dans un temps
raisonnable car le nombre de résumés possibles à considérer est trop grand
(exponentiel en nombre de phrases).

Or, pour estimer $f$, on n'a pas \textbf{besoin} de vérifier tous les résumés
possibles: on peut seulement se limiter à piger à quelques reprises de la distribution
de résumés générée par $\phi(\pi(d))$.

On procède donc par un échantillonnage de Monte-Carlo (\ref{souschap:mcs}), où on
calcule plutôt

\begin{equation}
    \bar{f} = \frac{1}{N} \sum_{t=1}^N R(s_t, \hat{s}),
\end{equation}

avec les résumés $s_t$ échantillonnés selon $\phi(\pi(d))$.

\section{Expériences sur l'échantillonnage}

On valide la rapidité de la convergence de $\bar{f}$ vers $f$ en les comparant
directement sur un sous-ensemble du jeu de données CNN/DailyMail.

Pour les tests, on prend 10 000 documents d'entraînement du jeu de données.

On pige aléatoirement des distributions $\pi(d)$ sur les phrases de chacun des documents.
Pour assurer une bonne variété dans les distributions explorées, on choisit des
distributions représentant une moyenne pondérée entre une distribution uniforme
$U(d)$ et une distribution \textit{3-hot} $G(d)$ :

\begin{equation}
    \pi(d) = (1 - \tau) U(d) + \tau G(d).
\end{equation}

On explore $\tau \in \{\frac{n}{100}: 0 \leq n \leq 100\}$ en repigeant les 3
index non-nuls de $G(d)$ à chaque fois. On ajoute un bruit gaussien sur chaque $\pi(d)$.

On calcule analytiquement $f$ grâce au fait que l'on possède tous les scores
ROUGE de tous les résumés possibles pour les documents du jeu de données.
On pige 1000 échantillons de $\phi(\pi(d))$, où $\phi$ est le processus de
pige sans remise de 3 phrases.

On pige enfin 1000 résumés de $\phi(\pi(d))$, nous donnant des estimés $\bar{f}_t$
pour $t$ allant de 1 à 1000.

La mesure de qualité à laquelle on s'intéresse ici est l'erreur d'échantillonnage,
que l'on définit naturellement comme la différence absolue entre $f$ et $\bar{f_t}$
: $\left|f - \bar{f_t}\right|$.

\section{Résultats échantillonnage}

\commentaire{Pour les tableaux, je veux surtout votre input sur (1) la pertinence
    de chacun, (2) la manière de les présenter (j'ai les données brutes, je peux
    facilement réorganiser comment je présente les donnnées) et (3) s'il y a des
    expériences supplémentaires que vous jugez pertinentes.}

\tikzsetnextfilename{mcs_overall}
\begin{figure}[h!]
    \begin{center}
        \begin{tikzpicture}
            \begin{axis}[title={Erreur de l'échantillonnage selon la taille des documents}, grid style={dashed,gray!50}, axis y line*=left, axis x line*=bottom, every axis plot/.append style={line width=1.5pt, mark size=0pt, font=\huge}, name=plot0, xshift=-.1\textwidth, y tick label style={/pgf/number format/fixed zerofill}, ylabel={$\left|f - \bar{f_t}\right|$}, xlabel={Nombre d'échantillons}, width=0.95\textwidth, height=0.4\textwidth, smooth, xmin=0, xmax=50]
                \addplot[blue, ylabel near ticks, line width=3pt] table[x=x, y=y, col sep=comma]{mcs/mcsExpResults/overall/mean.csv};
                \addplot[red, ylabel near ticks, line width=3pt] table[x=x, y=y, col sep=comma]{mcs/mcsExpResults/overall/less20.csv};
                \addplot[green, ylabel near ticks, line width=3pt] table[x=x, y=y, col sep=comma]{mcs/mcsExpResults/overall/20to35.csv};
                \addplot[yellow, ylabel near ticks, line width=3pt] table[x=x, y=y, col sep=comma]{mcs/mcsExpResults/overall/more35.csv};
                \legend{Moyenne, $|d| \leq 20$, $20 < |d| < 35$, $35 \leq |d|$}
            \end{axis}
        \end{tikzpicture}
    \end{center}
    \caption{Impact de la taille du document en entrée sur l'erreur d'échantillonnage.}
    \label{fig:mcs_overall}
\end{figure}

\tikzsetnextfilename{mcs_entropy}
\begin{figure}[h!]
    \begin{center}
        \begin{tikzpicture}
            \begin{axis}[title={Erreur de l'échantillonnage selon l'entropie}, grid style={dashed,gray!50}, axis y line*=left, axis x line*=bottom, every axis plot/.append style={line width=1.5pt, mark size=0pt, font=\huge}, name=plot0, xshift=-.1\textwidth, y tick label style={/pgf/number format/fixed zerofill}, ylabel={$\left|f - \bar{f_t}\right|$}, xlabel={Entropie}, width=0.95\textwidth, height=0.4\textwidth, smooth]
                \addplot[blue, ylabel near ticks, line width=3pt] table[x=x, y=t8, col sep=comma]{mcs/mcsExpResults/entropy/all.csv};
                \addplot[red, ylabel near ticks, line width=3pt] table[x=x, y=t16, col sep=comma]{mcs/mcsExpResults/entropy/all.csv};
                \addplot[green, ylabel near ticks, line width=3pt] table[x=x, y=t32, col sep=comma]{mcs/mcsExpResults/entropy/all.csv};
                \addplot[yellow, ylabel near ticks, line width=3pt] table[x=x, y=t64, col sep=comma]{mcs/mcsExpResults/entropy/all.csv};
                \legend{$t=8$, $t=16$, $t=32$, $t=64$}
            \end{axis}
        \end{tikzpicture}
    \end{center}
    \caption{Impact de l'entropie de la distribution des résumés sur l'erreur d'échantillonnage.}
    \label{fig:mcs_entropy}
\end{figure}


\tikzsetnextfilename{mcs_top3}
\begin{figure}[h!]
    \begin{center}
        \begin{tikzpicture}
            \begin{axis}[title={Erreur de l'échantillonnage selon la plus grande probabilité présente}, grid style={dashed,gray!50}, axis y line*=left, axis x line*=bottom, every axis plot/.append style={line width=1.5pt, mark size=0pt, font=\huge}, name=plot0, xshift=-.1\textwidth, y tick label style={/pgf/number format/fixed zerofill}, ylabel={$\left|f - \bar{f_t}\right|$}, xlabel={Probabilité maximale de $\phi(\pi(d))$}, width=0.95\textwidth, height=0.4\textwidth, smooth]
                \addplot[blue, ylabel near ticks, line width=3pt] table[x=x, y=t8, col sep=comma]{mcs/mcsExpResults/top3/all.csv};
                \addplot[red, ylabel near ticks, line width=3pt] table[x=x, y=t16, col sep=comma]{mcs/mcsExpResults/top3/all.csv};
                \addplot[green, ylabel near ticks, line width=3pt] table[x=x, y=t32, col sep=comma]{mcs/mcsExpResults/top3/all.csv};
                \addplot[yellow, ylabel near ticks, line width=3pt] table[x=x, y=t64, col sep=comma]{mcs/mcsExpResults/top3/all.csv};
                \legend{$t=8$, $t=16$, $t=32$, $t=64$}
            \end{axis}
        \end{tikzpicture}
    \end{center}
    \caption{Impact de la probabilité maximale de la distribution des résumés sur l'erreur d'échantillonnage.}
    \label{fig:mcs_top3}
\end{figure}

Les résultats obtenus sont rapportés dans les figures \ref{fig:mcs_overall}, \ref{fig:mcs_entropy}
et \ref{fig:mcs_top3}.

Tout d'abord, sur la figure \ref{fig:mcs_overall}, on remarque que le nombre de phrases dans un document n'est pas un
facteur déterminant sur la rapidité de convergence de l'échantillonnage de Monte-Carlo.
Ce résultat n'est pas surprenant: on peut s'attendre à ce que la difficulté
de convergence soit davantage qualifiée par une mesure sur la distribution
des résumés.

\todo{Rapporter nombre de phrases selon la taille (figure \ref{fig:mcs_overall})}.

Une première mesure naturelle sur la distribution des résumés est l'entropie,
définie pour une distribution $X$ quelconque comme :

\begin{equation*}
    H(X) = - \sum_{i=1}^n X_i \log X_i.
\end{equation*}

Important à savoir: entropie est 0 pour un one-hot, plus la distribution est près
d'une distribution uniforme, plus elle sera grande.

Analyse de (\ref{fig:mcs_entropy}): \commentaire{Je viens de réaliser que mon calcul d'entropie est fait sur la distribution des phrases et
    non pas sur la distribution des résumés. Je vais updater le graphe ASAP.
    Je vais updater l'analyse à ce moment.}

Enfin, c'est aussi pertinent de s'intéresser à l'impact qu'a la valeur maximale de
la distribution.
La figure (\ref{fig:mcs_top3}) nous montre une courbe à la tendance logarithmique,
où plus la grande probabilité de la distribution augmente, plus rapide est la convergence
de notre processus d'échantillonnage.

Globalement, on remarque aussi que la convergence est rapide.
Une différence de moins de 1 $R$ est définitivement suffisante pour faire un
apprentissage.
Les résultats indiquent de faire 16 échantillonnages semble être un bon compromis
performance-temps d'exécution.
C'est d'ailleurs cette valeur qui est utilisée dans les articles de \citep{dong2018banditsum}
et \citep{luo-etal-2019-reading}.

\section{Intégration dans un modèle complet}

Pour un modèle avec des paramètres $\theta$, on souhaite maximiser
la fonction objectif

\begin{equation}
    J(\theta) = f = \underset{{s \sim \phi(\pi(d))}}{\mathbb{E}} \,\left[R(s, \hat{s})\right].
\end{equation}

Comme on a vu qu'on peut approximer $f$ efficacement avec $\bar{f_t}$, on peut se limiter
à utiliser ce dernier.
On peut alors utiliser l'ascension de gradient et mettre à jour les poids $\theta$
selon la règle

\begin{equation*}
    \theta = \theta + \nabla_\theta \frac{1}{N} \sum_{t=1}^N R(s_t, \hat{s}).
\end{equation*}

C'est exactement ce que fait BanditSUM \citep{dong2018banditsum}.

\question{Ici, je reprends la logique derrière les approches policy gradient (RENFORCE
    notamment) en RL. J'ai décidé que ce serait pas souhaitable de m'étaler sur quoique ce soit
    RL dans mon mémoire alors je sais pas à quel point je devrais prendre un moment
    pour mentionner que j'emprunte cette logique là à des travaux antérieurs.}

BanditSUM introduit une baseline pour stabiliser les gradients de J
et prend un document à la fois, en posant $N=16$.

\subsection{Expériences}

\commentaire{Dernière rencontre j'avais parlé de considérer un autre processus de génération
    de résumés que le sampling qui arrête à 3, mais après réflexion je pense pas que ça va
    apporter quelque chose tant que ça et que ça va juste alourdir la lecture. Je vais
    le garder pour une conclusion avec les avenues possibles pour les futurs travaux.}

\todo{Détails du processus d'entraînement complet BanditSUM}

\subsection{Résultats}

\commentaire{Les expériences pour BanditSUM sont en train de rouler. Je pense surtout
    rapporter la courbe de performance et le temps d'exécution. Peut-être aussi rapporter comme plafond l'état de l'art ?}

\section{Conclusion}

\todo{à faire une fois les résultats de BanditSUM en main}