\chapter{Bandit combinatoire}
\label{chap:bandit_combi}                   % étiquette pour renvois (à compléter!)

Un problème fondamental de l'apprentissage de 
systèmes de génération de résumés extractifs est l'indisponibilité
de cibles naturelles.
À cet effet, une façon de faire attrayante est de 
calculer un oracle (\ref{sec:extractive}) 
qui génère d'excellents résumés extractifs que 
l'on utilise comme cibles pour un entraînement.
Habituellement, ces cibles sont binaires et représentent 
l'inclusion ou non d'une phrase dans le résumé produit 
par l'oracle. 
L'utilisation de cibles binaires n'est pas sans faute.
Si 3 phrases peuvent constituer le résumé extractif optimal 
selon un oracle, il est bien possible que certaines 
autres phrases produisent tout de même d'excellents résumés 
et se voient assigner une cible nulle.

Nous proposons une approche basée sur un problème 
de bandit combinatoire permettant de générer des cibles 
plus riches que les cibles binaires.
En pénalisant moins drastiquement les phrases qui ne font 
pas partie du résumé extractif optimal mais qui 
génèrent d'excellents résumés extractifs, nos cibles 
permettent intuitivement de quantifier la \textit{qualité 
extractive} d'une phrase.

Dans ce chapitre, on présente comment la génération du résumé d'un document
peut être interprétée un problème de bandit combinatoire \citep{CESABIANCHI20121404}.
On monte ensuite comment l'algorithme Upper Confidence Bound (UCB) \citep{ucb} peut être utilisé 
pour résoudre ce type de problème et comment il peut être employé pour 
générer des cibles pour un système de génération de résumés.
L'applicabilité des cibles proposées est par la suite validée empiriquement 
à l'aide d'un jeu de données de développement.
Enfin, on présente comment ces cibles peuvent être utilisées pour 
l'apprentissage de systèmes de génération de résumés en proposant 
un nouvel algorithme que l'on nomme CombiSum.
On met CombiSum à l'épreuve sur notre cadre expérimental 
uniformisé pour juger de son efficacité.

\section{Formulation combinatoire}
\label{section:formulation_combi}

Le bandit combinatoire est une approche par bandit qui vise à étendre
la formulation multi-bras à des environnements où plusieurs actions
$a \in \mathcal{A}$ peuvent être sélectionnées
en même temps par l'apprenant.
Nous nous intéressons seulement à la variante dite multitâche \citep{banditalgs}, où
il y a un nombre fixé $m$ d'actions sélectionnées à
chaque pas de temps $t$, créant une \textit{super-action} $\mathcal{M} = \{a_1, ..., a_m\}$
pour laquelle l'environnement retourne une récompense $X_{\mathcal{M}, t}$.
L'objectif demeure la minimisation du pseudo-regret cumulatif \eqref{eq:regret_cumulatif}, 
mais celui-ci est désormais calculé entre
la \textit{super-action} optimale $\mathcal{M}^*$ et les \textit{super-actions}
choisies $\mathcal{M}_t$.

Tout l'intérêt de cette formulation vient de l'éventuelle relation entre les \textit{super-actions}.
Bien qu'il serait possible de formuler le bandit multitâche comme un bandit multi-bras où l'ensemble des
actions possibles est l'ensemble des \textit{super-actions} $\mathcal{M}$, cette formulation
risque d'être très peu efficace.
En effet, comme les actions $a \in \mathcal{A}$ sont partagées entre les diverses \textit{super-actions},
il est possible d'utiliser la récompense associée à une \textit{super-action} pour
déduire de l'information sur la récompense associée aux actions qui la composent.
Cette information sur les actions $a$ peut alors être utilisée pour guider le choix des
prochaines \textit{super-actions} et accélérer l'apprentissage.

\subsection{Application à la génération de résumé}

La génération du résumé d'un document $d$ peut être vue comme un bandit combinatoire où
les actions de base sont les phrases $d_i$ et les \textit{super-actions} $\mathcal{M}$
sont les résumés de 3 phrases possibles.
En choisissant la \textit{super-action} $\mathcal{M}_{\hat{s}}$ associée au résumé $\hat{s}$,
l'apprenant reçoit $\text{ROUGE}(\mathcal{M}_{\hat{s}}, s)$ comme récompense et peut mettre à jour ses
croyances sur les phrases $d_i$ de $\hat{s}$.
Pour alléger la notation, nous dirons désormais que la \textit{super-action} 
$\mathcal{M} = \{a_{i_1},a_{i_2},a_{i_3}\}$ est un résumé extractif 
où l'action $a_i$ correspond à la phrase $d_i$.

Notons d'abord que, comme on ne tient pas compte de l'ordre dans le cadre 
expérimental uniformisé décrit à la section \ref{section:problematique},
il est naturel de considérer que chaque phrase d'un résumé contribue à part égale
au score observé.
Implicitement, cela revient à faire l'hypothèse que la récompense associée à un résumé
$\mathcal{M}$ est la moyenne de la récompense associable à chaque phrase.
Or, comme le score ROUGE est basé sur un score F1 sur le résumé complet, cette hypothèse
n'est pas strictement vraie mais elle est intuitivement valide.
En effet, les phrases qui résument bien le document généreront des résumés aux scores
plus élevés et donc leur présence à elle seule doit contribuer à augmenter le score
associé à un résumé.

Maintenant que l'on a établi le cadre théorique entourant le problème de bandit 
combinatoire, une question demeure: comment peut-on le résoudre ?
La prochaine section répond à cette question en démontrant 
comment l'algorithme UCB peut être légèrement modifié pour 
être appliqué au bandit combinatoire.

\subsection{UCB pour bandit combinatoire}

Tel que décrit à la section \ref{subsec:ucb}, Upper Confidence Bound (UCB) est une approche permettant 
de minimiser le pseudo-regret cumulatif pour les problèmes de bandit stochastique.
Pour ce faire, UCB maintient des bornes supérieures UCB$_a(t)$ pour chaque action 
$a \in \mathcal{A}$ et chaque pas de temps $t$

\begin{equation}
    \text{UCB}_a(t) = \bar{x}_a(t) + \beta \sqrt{\frac{2\ln t}{n_a(t)}},
    \label{eq:UCB}
\end{equation}
où $\bar{x}_a(t)$ est la moyenne des récompenses reçues jusqu'au temps $t$ par l'action $a$,
$n_a(t)$ est le nombre de fois que l'action $a$ a été sélectionnée et $\beta$ est un
hyperparamètre régulant l'exploration.
Quand une action n'a pas encore été sélectionnée i.e. $n_a(t)=0$, on 
lui assigne UCB$_a = \infty$, forçant l'apprenant à sélectionner au moins 
une fois chaque action avant d'exploiter les moyennes $\bar{x}_a(t)$
dans son choix d'action.

Bien que UCB est conçu pour les problèmes de bandits stochastiques, 
l'approche peut être 
naturellement étendue au problème de bandit combinatoire.
En effet, il suffit alors de choisir à chaque pas de temps $t$ la \textit{super-action}
maximisant la borne supérieure définie par UCB sur les actions $a \in \mathcal{A}$.
Dans notre cas, cela revient à sélectionner la \textit{super-action} composée des trois actions
avec la borne supérieure maximale, i.e.

\begin{equation}
    \mathcal{M}_t = \text{3-}\argmax_{a \in \mathcal{A}} \text{UCB}_a(t),
    \label{eq:ucb_combi_rule}
\end{equation}

où UCB$_a(t)$ est défini selon \eqref{eq:UCB}.

La prochaine section décrit le premier volet de notre contribution:
l'utilisation de UCB pour la génération de cibles extractives 
d'un document. 

\section{Génération de cibles par UCB}
\label{sec:cibles_ucb}

Pour entraîner le réseau de neurones décrit à la section
\ref{subsec:archi}, il est possible d'employer 
des cibles extractives $y$ associées à chaque document $d$.
Intuitivement, ces cibles doivent représenter 
dans quelle mesure chacune des phrases $d_i$
correspond à une bonne phrase d'un point de vue extractif.
Naturellement, on prend $y_i \in [0, 1]$\footnote{Ici $y_i$ 
représente la cible associée à la phrase $d_i$. On utilisera aussi parfois $y_a$
pour représenter la cible associée à la phrase $a$.}, où un score 
près de 1 indique que la phrase $d_i$ permet de générer 
des résumés extractifs de haute qualité.

Sur le jeu de données CNN/DailyMail \citep{hermann2015teaching},
les cibles habituellement retenues sont produites par 
l'oracle proposé par \citet{10.5555/3298483.3298681} et décrit 
à la section \ref{sec:extractive}.
Mentionnons simplement que l'oracle est une heuristique qui 
génère un résumé extractif $\dot{s}$ de 3 phrases en sélectionnant 
une à une les phrases d'un document maximisant le score 
ROUGE.
Comme l'ordre des phrases n'impacte presque pas le score ROUGE (\ref{subsec:eval}),
le résumé choisi par l'oracle 
peut être vu comme un résumé de 3 phrases presque optimal
d'un document.
Ainsi, \citet{10.5555/3298483.3298681} proposent d'utiliser 
les cibles binaires indiquant la présence ou non d'une phrase 
dans le résumé $\dot{s}$ produit par l'oracle, i.e.

\begin{equation}
    y_i = \mathbb{I}\big[d_i \in \dot{s}\big],
    \label{eq:cibles_binaires}
\end{equation}
pour $\mathbb{I}$ la fonction identité retournant 1 quand 
son prédicat est vrai et 0 sinon.

En raison de leur nature binaire, les cibles obtenues selon \eqref{eq:cibles_binaires}
peuvent potentiellement être mal spécifiées.
En effet, si le résumé $\dot{s}$ produit par l'oracle est 
presque optimal au sens extractif, cela n'empêche pas 
que d'autres résumés $\dot{s}'$ peuvent obtenir un score ROUGE
très similaire. 
Or, les phrases de $\dot{s}'$ qui ne font pas partie de $\dot{s}$
se verront attribuer une cible de 0, alors qu'elles présentent 
tout de même une excellente \textit{extractivité}.

\subsection{Motivation}

Nous proposons un nouveau processus de génération de cibles 
permettant d'alléger ce problème en quantifiant 
directement dans quelle mesure une phrase est susceptible de générer 
des bons résumés extractifs.
Pour un document $d$, le processus exécute $T$ pas de temps UCB \eqref{eq:ucb_combi_rule}
sur le bandit combinatoire représentant la génération du résumé de $d$.
En minimisant le pseudo-regret, UCB identifie graduellement les 
bons résumés et, plus particulièrement, maintient une 
moyenne $\bar{x}_a$ des scores ROUGE reçus en sélectionnant la phrase $a$.

Étant donné un nombre de pas temps $T$ infini, UCB 
identifierait éventuellement le résumé $\mathcal{M}^*$ optimal.
À ce moment, les moyennes $\bar{x}_a$ convergeraient éventuellement à $R^*$, 
le meilleur score de résumé extractif d'un document, pour les phrases $a$ faisant
partie du résumé optimal.
Or, tout l'intérêt repose dans les moyennes $\bar{x}_a$ pour les 
phrases ne faisant pas partie du résumé optimal.
Comme UCB va progressivement choisir de meilleurs résumés en s'assurant 
de bien explorer l'espace des résumés possibles, la moyenne $\bar{x}_a$ associée 
à une phrase $a$ pourra servir d'estimateur de sa qualité extractive.

Intuitivement, la structure inhérente de la génération 
de résumés extractifs donne lieu à bon nombre de phrases aux 
potentiels extractifs similaires (quelques mots correspondant au résumé cible) 
et peu d'excellentes phrases, difficiles à discerner.
En minimisant le regret, UCB va donc naturellement obtenir plus d'échantillons de résumés contenant 
les excellentes phrases.
Or, comme les excellentes phrases sont limitées, il faut échantillonner plus de résumés les contenant
avant d'obtenir une bonne estimation de leur valeur, contrairement aux phrases insatisfaisantes 
dont la valeur est rapidement estimée après quelques échantillons.
Il est donc justifié d'utiliser les quantités mesurées par UCB pour obtenir de l'information 
sur toutes les phrases d'un document, pas seulement pour trouver le résumé optimal.

Concrètement, nous proposons d'utiliser les moyennes $\bar{x}_a$ produites 
par un UCB pour générer les cibles $y_a$ selon le processus suivant.
On commence par appliquer une mise à l'échelle min-max des moyennes $\bar{x}_a$.
Cette mise à l'échelle produit des moyennes normalisées $\bar{x}_a' \in [0, 1]$
en conservant proportions originales entre les moyennes.
Les $\bar{x}_a'$ sont ensuite utilisé pour produire les cibles $y_a$ selon

\begin{equation}
    y_a = 10^{-10(1 - \bar{x}_a')}.
    \label{eq:cibles_ucb}
\end{equation}

L'intuition derrière l'équation \eqref{eq:cibles_ucb} est qu'une phrase 
avec une moyenne 10 \% inférieure à une autre devrait se voir attribuer une cible 
10 fois moins élevée. 
Cette mise à l'échelle peut sembler drastique mais il faut se souvenir 
que l'on ne souhaite accorder d'importance qu'aux phrases qui produisent 
d'excellents résumés.
Enfin, grâce à la mise à l'échelle min-max préalable, une cible de 1 
sera toujours associée pour la meilleure phrase selon UCB.

\subsection{Expériences}

Si l'intuition de l'utilisation des quantités calculées par UCB comme cibles est naturelle
pour le cas où le nombre de pas de temps $T$ effectué est immense, il demeure néanmoins important
de vérifier comment ces cibles sont adéquates sur un nombre de pas de temps plus restreint.
Mais, comment savoir quand on approche de ce stade d'optimalité et que 
l'on peut considérer les cibles comme adéquates ?
Réponse: quand le score du résumé le plus prometteur selon les moyennes $\bar{x}_a$, nommons le $R_t$,
commence à converger vers le score $R^*$ du résumé extractif optimal.
En mesurant la sous-optimalité $\Delta_t = R^* - R_t$ des cibles générées
par UCB, on peut donc savoir à partir de quel moment les cibles seraient satisfaisantes
pour être utilisées en entraînement.

On reprend donc le jeu de développement présenté à la section \ref{subsec:jeu_donnees} 
pour mener des expériences sur la rapidité de l'obtention de cibles satisfaisante par UCB.
Les résultats des figures \ref{fig:bandit_combi_alpha}
et \ref{fig:bandit_combi_doc_len} sont obtenus en calculant les $\Delta_t$ à partir de
l'algorithme \ref{alg:cible_ucb}.
Notons que, pour mettre UCB à l'échelle de chaque document $d$, 
l'exploration que l'on utilise est plutôt guidée par $\beta' = \frac{\beta}{|d|}$.
Il est aussi à noter que les différences rapportées entre les différentes 
courbes sur les figures ne sont pas statistiquement significatives.
Pour éviter d'encombrer inutilement les figures, on rapporte alors 
seulement les moyennes observées.
Les versions incorporant la déviation standard des différentes courbes 
se trouvent à l'annexe \ref{chap:variance_graphs}.

\begin{algorithm}
    \setstretch{1.3}
    \caption{UCB combinatoire pour génération de résumé}
    \begin{algorithmic}[1]
        \Require $d$ (document), $s$ (résumé cible), $\beta$ (paramètre d'exploration), $T$ (nombre de pas de temps).
        \State Initialiser $\bar{x}_a =0$ et $n_a = 0$ pour $a \in d$
        \For{$t=1, ..., T$}
        \For{$a \in d$}
        \State UCB$_a = \bar{x}_a + \frac{\beta}{|d|} \sqrt{\frac{2 \ln t}{n_a}}$
        \EndFor
        \State $\mathcal{M}_t =$ 3-$\argmax$ UCB$_a$
        \State $r_t = \text{ROUGE}(\mathcal{M}_t, s)$
        \State Mettre à jour $\bar{x}_a$ et $n_a$ pour {$a \in \mathcal{M}_t$}
        \EndFor
    \end{algorithmic}
    \label{alg:cible_ucb}
\end{algorithm}

\subsection{Résultats}
\label{subsec:ucb_resultats}

% La figure \ref{fig:bandit_combi_q_argmax} présente l'importance du critère de sélection
% utilisé pour trouver le résumé optimal selon UCB au temps $t$.
% Deux approches sont envisageables: considérer les phrases $i$ où la moyenne des récompenses reçues
% $\bar{x}_i$ est maximale ou encore celles où le nombre de sélections $n_i$ est maximal.
% Les résultats rapportés donnent un net avantage aux résumés sélectionnés selon la moyenne des
% récompenses perçues.
% C'est normal: les $n_i$ prennent beaucoup plus de temps à distinguer les bonnes phrases
% car ils sont issus d'une distribution uniforme pour la sélection des $|d|$ premières phrases.
% Remarquons aussi que les deux approches convergent éventuellement au même résumé optimal,
% comme c'était à prévoir.
% Enfin, la conclusion retenue est que les $\bar{x}_i$ forment de meilleurs cibles que les $n_i$.
% Pour les prochaines figures, les résultats rapportés seront donc seulement ceux obtenus 
% selon le critère de sélection basés sur $\bar{x}_i$.

% \tikzsetnextfilename{bandit_combi_q_argmax}
% \begin{figure}[h!]
%     \begin{center}
%         \begin{tikzpicture}
%             \begin{axis}[title={Critère de sélection du résumé retenu}, grid style={dashed,gray!50}, axis y line*=left, axis x line*=bottom, every axis plot/.append style={line width=1.5pt, mark size=0pt, font=\huge}, name=plot0, y tick label style={/pgf/number format/fixed zerofill}, ylabel={$\Delta_t$}, xlabel={$t$}, width=0.95\textwidth, height=0.4\textwidth, smooth, xmin=0, xmax=100, y tick label style={/pgf/number format/fixed}]
%                 \addplot[green, ylabel near ticks, line width=3pt] table[x=t, y=arg_1e1, col sep=comma]{bandit_combi/bandit_combiExpResults/alpha/all.csv};
%                 \addplot[blue, ylabel near ticks, line width=3pt] table[x=t, y=q_1e1, col sep=comma]{bandit_combi/bandit_combiExpResults/alpha/all.csv};
%                 \legend{$n_i$, $\bar{x_i}$}
%             \end{axis}
%         \end{tikzpicture}
%     \end{center}
%     \caption{Impact du critère de sélection utilisé pour choisir le résumé retenu au temps $t$.}
%     \label{fig:bandit_combi_q_argmax}
% \end{figure}

La figure \ref{fig:bandit_combi_alpha} présente comment l'hyperparamètre $\beta$ influence la
convergence de UCB.
On remarque que $\beta=10$ (courbe verte sur la figure) semble être le bon compromis entre exploration et exploitation,
réussissant à converger à $\Delta_t \approx 0.05$ après 250 pas de temps de UCB.

\tikzsetnextfilename{bandit_combi_alpha}
\begin{figure}[h!]
    \begin{center}
        \begin{tikzpicture}
            \begin{axis}[title={Impact de l'exploration sur la progression de la sous-optimalité}, grid style={dashed,gray!50}, axis y line*=left, axis x line*=bottom, every axis plot/.append style={line width=1.5pt, mark size=0pt, font=\huge}, name=plot0, y tick label style={/pgf/number format/fixed zerofill}, ylabel={$\Delta_t$}, xlabel={$t$}, width=0.95\textwidth, height=0.4\textwidth, smooth, xmin=0, xmax=250, y tick label style={/pgf/number format/fixed}]
                \addplot[red, ylabel near ticks, line width=3pt] table[x=t, y=q_1e0, col sep=comma]{bandit_combi/bandit_combiExpResults/alpha/all.csv};
                \addplot[green, ylabel near ticks, line width=3pt] table[x=t, y=q_1e1, col sep=comma]{bandit_combi/bandit_combiExpResults/alpha/all.csv};
                \addplot[blue, ylabel near ticks, line width=3pt] table[x=t, y=q_1e2, col sep=comma]{bandit_combi/bandit_combiExpResults/alpha/all.csv};
                \legend{$\beta = 1$, $\beta = 10$, $\beta = 100$}
            \end{axis}
        \end{tikzpicture}
    \end{center}
    \caption{Impact du paramètre d'exploration $\beta$ utilisé par UCB sur la convergence.
    $\Delta_t$ représente la différence entre le score ROUGE du meilleur résumé selon UCB et 
    celui généré par l'oracle.}
    \label{fig:bandit_combi_alpha}
\end{figure}

La figure \ref{fig:bandit_combi_doc_len} évalue dans quelle mesure la taille des documents
influe sur la sous-optimalité des cibles générées par UCB.
On remarque d'abord que $\beta=10$ (courbe verte) est la meilleure configuration pour toutes les tailles
de document.
Il est donc adéquat de prendre la même valeur de $\beta$ pour tous les documents.

Aussi, on remarque que l'apprentissage converge plus tôt pour les documents qui sont
plus courts.
Il serait donc pertinent de faire croître le nombre de pas de temps de UCB en fonction du nombre de
phrases dans un document.
À cette fin, on remarque que la performance stagne autour de 100 pas de temps pour les documents 
courts mais continue à augmenter jusqu'à 250 pas de temps pour les longs documents.

\begin{figure}[h!]
    \tikzsetnextfilename{bandit_combi_less20}
    \begin{tikzpicture}[baseline]
        \begin{axis}[grid style={dashed,gray!50}, axis y line*=left, axis x line*=bottom, every axis plot/.append style={line width=1.5pt, mark size=0pt, font=\Large}, width=0.35\textwidth,
                height=0.4\textwidth, name=plot0, y tick label style={/pgf/number format/fixed zerofill}, xmin=0.0, xmax=250.0, ymin=0.01, ymax=0.30, ylabel={$\Delta_t$}, xlabel={$t$}, smooth, title={$|d| \leq 20$}]
            \addplot[red, ylabel near ticks, line width=3pt] table[x=t, y=less20_1e0, col sep=comma]{bandit_combi/bandit_combiExpResults/doc_len/all.csv};
            \addplot[green, ylabel near ticks, line width=3pt] table[x=t, y=less20_1e1, col sep=comma]{bandit_combi/bandit_combiExpResults/doc_len/all.csv};
            \addplot[blue, ylabel near ticks, line width=3pt] table[x=t, y=less20_1e2, col sep=comma]{bandit_combi/bandit_combiExpResults/doc_len/all.csv};
            \legend{$\beta=1$, $\beta=10$, $\beta=100$}
        \end{axis}
    \end{tikzpicture}
    \tikzsetnextfilename{bandit_combi_20to35}
    \begin{tikzpicture}[baseline]
        \begin{axis}[grid style={dashed,gray!50}, axis y line*=left, axis x line*=bottom, every axis plot/.append style={line width=1.5pt, mark size=0pt, font=\huge}, width=.35\textwidth,
                height=0.4\textwidth, name=plot0, xshift=-.1\textwidth, y tick label style={/pgf/number format/fixed zerofill},xmin=0.0, xmax=250.0, ymin=0.01, ymax=0.30, xlabel={$t$}, legend style={at={(0.9,0.1)},anchor=south east}, smooth, title={$20 < |d| < 35$}, ymajorticks=false]
            \addplot[red, ylabel near ticks, line width=3pt] table[x=t, y=20to35_1e0, col sep=comma]{bandit_combi/bandit_combiExpResults/doc_len/all.csv};
            \addplot[green, ylabel near ticks, line width=3pt] table[x=t, y=20to35_1e1, col sep=comma]{bandit_combi/bandit_combiExpResults/doc_len/all.csv};
            \addplot[blue, ylabel near ticks, line width=3pt] table[x=t, y=20to35_1e2, col sep=comma]{bandit_combi/bandit_combiExpResults/doc_len/all.csv};
        \end{axis}
    \end{tikzpicture}
    \tikzsetnextfilename{bandit_combi_more35}
    \begin{tikzpicture}[baseline]
        \begin{axis}[grid style={dashed,gray!50}, axis y line*=right, axis x line*=bottom, every axis plot/.append style={line width=1.5pt, mark size=0pt, font=\huge}, width=.35\textwidth,
                height=0.4\textwidth, name=plot0, xshift=-.1\textwidth, y tick label style={/pgf/number format/fixed zerofill}, xmin=0.0, xmax=250.0, ymin=0.01, ymax=0.30, xlabel={$t$}, legend style={at={(1,0.1)},anchor=south east}, smooth, title={$35 \leq |d|$}]
            \addplot[red, ylabel near ticks, line width=3pt] table[x=t, y=more35_1e0, col sep=comma]{bandit_combi/bandit_combiExpResults/doc_len/all.csv};
            \addplot[green, ylabel near ticks, line width=3pt] table[x=t, y=more35_1e1, col sep=comma]{bandit_combi/bandit_combiExpResults/doc_len/all.csv};
            \addplot[blue, ylabel near ticks, line width=3pt] table[x=t, y=more35_1e2, col sep=comma]{bandit_combi/bandit_combiExpResults/doc_len/all.csv};
        \end{axis}
    \end{tikzpicture}
    \caption{Impact de la taille du document sur la convergence de UCB.
    $\Delta_t$ représente la différence entre le score ROUGE du meilleur résumé selon UCB et 
    celui généré par l'oracle.}
    \label{fig:bandit_combi_doc_len}
\end{figure}


\section{CombiSum}
\label{sec:combisum}

On propose maintenant un algorithme basé sur les cibles 
générées par UCB: CombiSum.
Conformément au cadre expérimental uniformisé présenté à la section 
\ref{section:problematique},
CombiSum réutilise exactement la même architecture neuronale que BanditSum.
Conformément aux méthodes de l'état de l'art sur l'apprentissage 
de cibles \citep{liu2019text}, la mise à jour des paramètres est faite selon la 
perte basée sur l'entropie croisée binaire entre une cible $y$
et un vecteur d'affinités produit $\hat{y} = \pi_\theta(d)$:

\begin{equation}
    l(\hat{y}, y) = \frac{1}{|y|} \sum_{i=1}^{|y|}\big[y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i) \big].
    \label{eq:bce}
\end{equation}

En se basant sur les résultats de la section précédente, on explore deux 
fonctions $T(d)$ déterminant le nombre $T$ de pas de temps utilisés pour 
générer les cibles UCB pour un document $d$.
Premièrement, on considère une version fixe $T_f(d)=100$, correspondant à une 
bonne estimation pour toutes les tailles de document.
On considère aussi une version $T_l(d)=2|d| + 50$ augmentant linéairement selon 
le nombre de phrases d'un document.
Comme notre régularisation limite les documents à 50 phrases ou moins, 
$T_l(d)$ varie entre 50 et 150, avec une moyenne (sur les tailles de document) à 
100.
Ainsi, $T_f$ et $T_l$ utiliseront le même nombre de pas de temps en moyenne 
et il sera possible de valider laquelle des deux fonctions permet 
le meilleur entraînement.

\subsection{Expériences}

Une description détaillée de CombiSum est fournie à l'algorithme \ref{alg:systeme_ucb}.
On effectue un entraînement sur le jeu de données CNN/DailyMail en 
parcourant dans son entièreté le jeu de d'entraînement à 5 reprises
et en utilisant des \textit{minibatches} de taille $B=64$.
Notre implémentation est faite selon les détails expérimentaux décrits à la section 
\ref{subsec:archi}.

\begin{algorithm}
    \setstretch{1.3}
    \caption{CombiSum}
    \begin{algorithmic}[1]
        \Require  $\mathcal{D}$ (jeu de données), $T$ (fonction pour le nombre de pas de temps), $\alpha$ (taux d'apprentissage), $\beta$ (taux d'exploration UCB), $B$ (taille de minibatch).
        \While{vrai}
        \State{batch $\sim \mathcal{D}^B$} \Comment{On pige la minibatch du jeu de données}
        \State $\nabla = \mathbf{0}$
        \ForAll{$(d,s) \in $ batch}
        \State $\hat{y} = \pi_\theta(d)$
        \State Exécuter $T(d)$ pas de temps de UCB et obtenir $\bar{x}$.
        \State Générer les cibles $y$ à partir de $\bar{x}$ \Comment{Selon \eqref{eq:cibles_ucb}}
        \State $\nabla = \nabla + \nabla_\theta l(\hat{y}, y)$ \Comment{Selon \eqref{eq:bce}}
        \EndFor
        \State $\theta = \theta - \alpha \nabla$
        \EndWhile
    \end{algorithmic}
    \label{alg:systeme_ucb}
\end{algorithm}

Pour les expériences, on s'intéresse à
l'impact de la fonction $T$ utilisée.
On expérimente donc avec $T = T_f$ et $T=T_l$,
tel que décrits plus haut.
En guise de référence, on entraîne aussi un modèle 
en utilisant les cibles binaire générées par l'oracle.
Étant donné le facteur aléatoire présent dans l'entraînement, nous effectuons 
5 entraînements distincts pour chaque $T$ et présentons la moyenne
des résultats obtenus.

\subsection{Résultats}

Les résultats obtenus sont présentés dans la figure \ref{fig:cs_learning_curve} 
et le tableau \ref{tab:ROUGE_UCB}.
Ici, UCB linéaire et fixe font référence respectivement à l'utilisation
à l'utilisation $T_l$ et $T_f$ pour déterminer le nombre de pas de temps
effectués par UCB.

Tout d'abord, la figure \ref{fig:cs_learning_curve} illustre l'évolution 
de la performance sur le jeu de validation des modèles selon 
les cibles utilisées.
On constate d'abord que la performance en validation avec les cibles 
UCB atteint rapidement un plateau à partir duquel elle 
ne varie plus.
Ce plateau n'affecte toutefois pas l'entraînement avec les cibles binaires,
avec lesquelles l'apprentissage continue de varier jusqu'à
éventuellement dépasser légèrement la performance des cibles UCB.

\tikzsetnextfilename{combisum_learning_curve}
\begin{figure}[h!]
    \begin{center}
        \begin{tikzpicture}
            \begin{axis}[title={Performance sur le jeu de validation selon la cible utilisée}, grid style={dashed,gray!50}, axis y line*=left, axis x line*=bottom, every axis plot/.append style={line width=1.5pt, mark size=0pt, font=\huge}, name=plot0, y tick label style={/pgf/number format/fixed zerofill}, ylabel={ROUGE}, xlabel={Nombre de mises à jour (en milliers)}, width=0.95\textwidth, height=0.4\textwidth, smooth, xmin=0.5, legend style={at={(0.9,0.1)},anchor=south east}, legend cell align={left}, xmax=22.5, y tick label style={/pgf/number format/fixed}]
                \addplot[blue, ylabel near ticks, line width=2pt] table[x=t, y=sit_fix, col sep=comma]{bandit_combi/graham_results/cs_learning_curve.csv};
                \addplot[forget plot, name path=upperblue, draw=none] table[x=t, y=sit_fix_+, col sep=comma]{bandit_combi/graham_results/cs_learning_curve.csv};
                \addplot[forget plot, name path=lowerblue, draw=none] table[x=t, y=sit_fix_-, col sep=comma]{bandit_combi/graham_results/cs_learning_curve.csv};
                \addplot[red, ylabel near ticks, line width=2pt] table[x=t, y=sit_linear, col sep=comma]{bandit_combi/graham_results/cs_learning_curve.csv};
                \addplot[forget plot, name path=upperred, draw=none] table[x=t, y=sit_linear_+, col sep=comma]{bandit_combi/graham_results/cs_learning_curve.csv};
                \addplot[forget plot, name path=lowerred, draw=none] table[x=t, y=sit_linear_-, col sep=comma]{bandit_combi/graham_results/cs_learning_curve.csv};
                \addplot[green, ylabel near ticks, line width=2pt] table[x=t, y=binary_linear, col sep=comma]{bandit_combi/graham_results/cs_learning_curve.csv};
                \addplot[forget plot, name path=uppergreen, draw=none] table[x=t, y=binary_linear_+, col sep=comma]{bandit_combi/graham_results/cs_learning_curve.csv};
                \addplot[forget plot, name path=lowergreen, draw=none] table[x=t, y=binary_linear_-, col sep=comma]{bandit_combi/graham_results/cs_learning_curve.csv};
                \addplot[fill=blue!20, fill opacity=0.5] fill between[of=upperblue and lowerblue];
                \addplot[fill=red!20, fill opacity=0.5] fill between[of=upperred and lowerred];
                \addplot[fill=green!20, fill opacity=0.5] fill between[of=uppergreen and lowergreen];
                \legend{UCB fixe, UCB linéaire, Oracle}
            \end{axis}
        \end{tikzpicture}
    \end{center}
    \caption{Courbe d'apprentissage de CombiSum selon la cible UCB utilisée.
             Un intervalle de confiance à 95 \% calculé à partir de 5 entraînements distincts
             est rapporté pour chaque cible.}
    \label{fig:cs_learning_curve}
\end{figure}

Le tableau \ref{tab:ROUGE_UCB} présente la performance 
obtenue par nos modèles et par la référence Lead-3 sur le jeu de test.
Pour chaque entraînement effectué, la performance en test 
rapportée est celle obtenue avec les paramètres $\theta$
permettant d'obtenir la meilleure performance en validation.

\begin{table}[!h]
    \centering
    \def\arraystretch{1.8}
    \resizebox{0.8\textwidth}{!}{%
    \begin{tabular}{ccccc}
    \specialrule{.2em}{.1em}{.1em}
    \multicolumn{1}{c}{\textbf{Cible utilisée}} & \multicolumn{1}{c}{\textbf{ROUGE-1}} & \multicolumn{1}{c}{\textbf{ROUGE-2}} & \multicolumn{1}{c}{\textbf{ROUGE-L}} & \multicolumn{1}{c}{\textbf{ROUGE}} \\ \specialrule{.2em}{.1em}{.1em}
    Lead-3 & 39.59  & 17.68 & 36.21 & 31.16\\ \specialrule{.1em}{.05em}{.05em}
    UCB fixe & $40.04 \pm 0.11$  & $\mathbf{18.18 \pm 0.14}$  & $36.46 \pm 0.15$ & $\mathbf{31.56 \pm 0.13}$\\
    UCB linéaire & $40.07 \pm 0.09$  & $\mathbf{18.21 \pm 0.10}$ & $36.49 \pm 0.10$ & $\mathbf{31.59 \pm 0.10}$ \\ 
    Oracle & $\mathbf{40.47 \pm 0.27}$ & $\mathbf{18.21 \pm 0.15}$ & $\mathbf{36.93 \pm 0.24}$ & $\mathbf{31.87 \pm 0.22}$ \\\specialrule{.2em}{.1em}{.1em}
    \end{tabular}
    }
    \caption{Performance sur le jeu de test.}
    \label{tab:ROUGE_UCB}
\end{table}

Un premier constat qui se pose est que, peu importe la cible 
utilisée, les modèles produits se comportent de manière 
extrêmement similaire sur le jeu de test.
Aussi, la performance obtenue n'est que 
très légèrement supérieure à Lead-3.

En somme, les résultats obtenus par CombiSum sont décevants,
ne se distinguant que très légèrement de la référence Lead-3.
Nous élaborons davantage sur les potentielles 
justifications de cette performance et discutons 
d'une piste de solution envisageable au chapitre \ref{chap:analyse_convergemce}.

\section{Conclusion}

Dans ce chapitre, nous avons proposé de nouvelles cibles plus riches
pour l'entraînement d'un modèle de génération de résumés.
Nos nouvelles cibles sont basées sur une version 
de UCB adaptée au bandit combinatoire, dont nous avons validé 
l'applicabilité sur notre jeu de développement.
Enfin, nous avons présenté comment les cibles 
peuvent être utilisées dans un algorithme 
que nous avons nommé CombiSum.

Le prochain chapitre présente une autre 
formulation bandit pouvant être utilisée pour 
générer des cibles riches: le bandit combinatoire 
linéaire.
En mode linéaire, le bandit combinatoire peut être résolu 
encore plus rapidement et le prochain chapitre 
représente donc une version potentiellement plus 
efficace des cibles présentées dans ce chapitre.