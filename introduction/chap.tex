\chapter*{Introduction}
\label{chap:introduction}

Lors d'une entrevue en 2018, le président de la multinationale Siemens 
mentionnait que "Data is the oil, some say the gold, of the 21st century
— the raw material that our economies, societies and democracies are 
increasingly being built on”. 
Son affirmation, partagée par bon nombre d'experts dans le domaine de la
technologie, décrit ce que l'on appelle communément l'ère du \textit{Big Data}.
Cette appellation vise à décrire la quantité immense de données maintenant 
générées et collectées par le traffic internet ou encore les appareils de 
l'Internet des ObjeTs (IoT), pour n'en nommer que quelques-uns.

Dans la panoplie de données à disposition se trouvent les données textuelles, 
issues par exemple d'interactions sur des réseaux sociaux ou encore de documents 
numériques.
Ces données textuelles présentent une opportunité d'affaires en or à qui saura
les utiliser.
En effet, des traitements requérant habituellement l'avis d'un expert humain 
peuvent se voir automatiser par des modèles entraînés à reproduire le comportement
des experts sur les données disponibles.
Il suffit de penser aux cas des agents conversationnels pour le service à 
la clientèle ou des détecteurs automatiques de contenus toxiques 
sur les sites webs pour réaliser l'immense potentiel apporté par l'abondance
des données textuelles.

Ce ne sont toutefois pas tous les domaines utilisant des données textuelles 
qui peuvent être automatisables en entièreté.
Certains domaines, notamment en assurance, requièrent explicitement l'intervention 
d'un humain pour des raisons de législation.
Comment alors faire profiter du grand afflux de données dans ces systèmes où l'humain (et
sa capacité de traitement limitée) sont essentiels ?

Une option qui peut s'avérer facilement attrayante est l'idée de condenser un ou plusieurs
documents en un texte concis contenant seulement l'information requise pour procéder à la
tâche à exécuter.
On dit alors que l'on fait appel à un système de génération automatique de résumés de textes.
Ces systèmes sont le sujet principal du présent document.

Plus particulièrement, on s'intéresse à une nouvelle approche basée sur une formulation 
de la génération de résumé comme un problème de bandit.
Les problèmes de bandit sont des problèmes étudiés depuis le début du 20ème
siècle, dont la résolution est basée sur l'obtention rapide d'une bonne solution.
En voyant le génération de résumé comme un bandit, on souhaite bâtir 
des systèmes de génération de résumés qui apprendront rapidement à générer 
des résumés satisfaisants grâce à une exploration efficace du vaste espace de résumés 
possibles. 

\section*{Objectifs}

Concrètement, ce document a pour objectifs de répondre aux questions suivantes:

\begin{itemize}
      \item Comment peut-on formuler la génération de résumés comme un problème de bandit multi-bras(MAB) ?
            Comment les algorithmes utilisés habituellement pour résoudre les MAB peuvent
            alors être appliqués à la génération de résumés ?
      \item Dans quelle mesure ces algorithmes de bandit sont-ils performants dans le contexte de résumés?
            Sont-ils plus rapides en temps de calcul ? En nombre d'échantillons requis pour une
            bonne performance ? Est-ce que les solutions auxquelles ils convergent sont meilleures ?
      \item Comment l'introduction de ces artefacts bandits a-t-elle affecté la performance ?
            Est-ce que les systèmes produits génèrent des résumés de meilleure qualité ?
            A-t-on besoin de moins d'exemples avant d'avoir un système de haute qualité ?
            Est-ce que l'entraînement est plus rapide à effectuer ? Avec quelles ressources de calcul ?
      \item Comment les performances de ces algorithmes se comparent-elles entre eux ? Et par rapport à l'état de l'art ?
\end{itemize}

On atteint les objectifs en proposant 3 formulations de bandits applicables au processus
de la génération de résumés.
Une des approches proposée est présente dans la littérature mais les deux autres sont
des nouveautés, du mieux de notre connaissance.

\section*{Structure du mémoire}

Ce mémoire débute par une introduction aux concepts de base essentiels à la compréhension
du reste du document.
Le document est ensuite divisé en trois chapitres pour les trois formulations de MAB explorées:
bandit contextuel, bandit combinatoire et bandit combinatoire linéaire.

Pour chacun des chapitres, on commence par définir le cadre bandit proposé.
Des expériences empiriques sont effectuées pour justifier l'applicabilité
du cadre au contexte de génération de résumés.
On montre ensuite comment le cadre bandit peut utilisé dans un nouvel algorithme
pour l'entraînement d'un système neuronal de génération automatique de résumés.
Enfin, on valide le comportement de l'algorithme en l'utilisant pour
entraîner plusieurs modèles de génération de résumés.
Les algorithmes sont comparés en fonction de leur rapidité de convergence et
de la qualité finale des modèles produits.