% !TeX root = ./main.tex
\chapter*{Introduction}
\label{chap:introduction}       % étiquette pour renvois

\question{
    À quel point est-ce que l'introduction doit déboucher exactement sur mon mémoire ?
    J'ai l'impression qu'à la fin de mon intro, le lecteur devrait être en contexte
    par rapport au titre, i.e. il devrait savoir qu'on va parler de (1) résumés, (2)
    méthodes de MC et (3) que tout ça va être fait avec des NN.
}

Ère du big data: on a une quantité immense de données, notamment textuelles.

Succès des dernières décennies nous montrent le potentiel qui peut se cacher
derrière une utilisation judicieuse de ces données.

Or, il n'est pas toujours possible d'incorporer toutes les données dans 
un processus de traitement.

Notamment, dans certains domaines, les humains sont encore requis dans la loop 
dans des applications de traitement de données textuelles en raison de 
législations ou d'assurance qualité (i.e. processus de réclamations en assurance).

Comment faire profiter du grand afflux de données dans des systèmes où l'humain (et 
sa capacité de traitement limitée) sont essentiels ?

Une option qui peut s'avérer facilement attrayante est l'idée de condenser un ou plusieurs
documents en un texte concis contenant seulement l'information requise pour procéder à la 
tâche à exécuter.

On dit alors que l'on fait appel à un système de génération automatique de résumés de textes.

Comment fonctionnent ces systèmes de génération de résumés ?

L'espace des résumés possibles est très vaste; comment faire pour en trouver un qui est
suffisamment bon dans un délai de temps assez raisonnable pour l'utilisation dans un contexte
du monde réel ?

Des outils probabilistes, connus sous le nom de méthodes de Monte-Carlo, ont été
spécifiquement conçus pour de tels contextes.

Ils se basent sur l'aléatoire pour parcourir efficacement des espaces potentiellement
très grands.

En les jumelant à des approches neuronales ayant démontré largement leur efficacité sur des données
textuelles, il est naturel de s'attendre à ce que ces outils permettent d'obtenir des 
systèmes de génération automatique qui produisent non seulement d'excellents résumés, mais qui
ne le font pas au détriment d'un temps d'entraînement déraisonnable.

\section*{Objectifs}

Dans ce mémoire, on explorera d'abord comment différentes méthodes de Monte-Carlo
peuvent être utilisées pour estimer des mesures liées à la qualité de résumés de textes
dont le calcul est difficile à première vue.

On verra ensuite comment ces approximations obtenues par des approches Monte-Carlo
peuvent être utilisées dans un système complet de génération de résumés.

Les différents systèmes explorés seront enfin comparés aux approches représentant
l'état de l'art en génération de résumés en fonction de leur efficacité d'entraînement
et de prédiction ainsi que selon la qualité des résumés produits.

\section*{Structure du mémoire}

Ce mémoire sera divisé en trois chapitres pour les trois méthodes de Monte-Carlo explorées:
échantillonnage, recherche arborescente et recherche arborescente linéaire.

Pour chacun des chapitres, on posera d'abord une fonction en lien avec la génération de résumé
qui est difficile à évaluer.

On montera ensuite comment une méthode Monte-Carlo
peut être utilisée pour l'approximer.

On évaluera empiriquement la rapidité
de la convergence de la méthode proposée.

On proposera ensuite un modèle neuronal
de génération automatique de textes utilisant la méthode MC à l'essai.

Des expériences seront ensuite effectuées pour évaluer la performance du modèle.

Les hyperparamètres de la portion MC seront choisis en fonction des tests
empiriques préliminaires.