\chapter{Bandit combinatoire linéaire}
\label{chap:bandit_combi_lin}                   % étiquette pour renvois (à compléter!)

L'approche combinatoire pure présentée au chapitre précédent présente un inconvénient
notoire: elle n'utilise pas de relation de similarité entre les phrases pour propager
de l'information entre deux phrases similaires.
Il est possible de faire cela sous la formulation du bandit combinatoire linéaire,
où on possède des représentations vectorielles de chacune des actions et on
fait l'hypothèse qu'il existe un vecteur propre au problème qui relie
les représentations de phrases à leur récompense espérée.

Ce chapitre suit une structure très similaire au chapitre précédent.
D'abord, on présente comment la génération du résumé d'un document
peut être interprétée un problème de bandit combinatoire \citep{CESABIANCHI20121404}
linéaire.
On montre ensuite comment l'algorithme Linear Upper Confidence Bound (LinUCB) 
\citep{chu2011contextual} peut être utilisé 
pour résoudre ce type de problème et comment il peut être employé pour 
générer des cibles pour un système de génération de résumés.
L'applicabilité des cibles proposées est par la suite validée empiriquement 
à l'aide d'un jeu de données de développement.
Enfin, on présente comment ces cibles peuvent être utilisées pour 
l'apprentissage de systèmes de génération de résumés en proposant 
un nouvel algorithme que l'on nomme LinCombiSum.
On met LinCombiSum à l'épreuve sur notre cadre expérimental 
uniformisé pour juger de son efficacité.

\section{Formulation combinatoire linéaire}

La formulation combinatoire linéaire n'est rien de plus que 
l'application du principe combinatoire (\ref{section:formulation_combi})
au bandit stochastique linéaire (\ref{subsec:bandit_lineaire}).
Pour garder la présentation digeste,
nous nous contentons de rapporter les différences clés 
introduites par la formulation linéaire et les modifications
aux équations pertinentes.

Pour un problème de bandit linéaire, on dit que l'on dispose 
de représentations vectorielles $\tilde{a} \in \tilde{\mathcal{A}} \subseteq \mathbb{R}^n$
des actions qui peuvent être sélectionnées par l'apprenant.
Il est supposé qu'il existe un vecteur de récompense $\omega_*$
reliant un action $\tilde{a}$ à son espérance de récompense $\mu_a$, i.e.
$\langle \omega_*, \tilde{a}\rangle \approx \mu_a$ pour tout $a$.

Cette formulation se généralise similairement à la 
variante multitâche du bandit combinatoire, où l'agent 
sélectionne $m$ actions à chaque pas de temps $t$.
Les vecteurs d'actions $\tilde{a}$ sélectionnés sont
additionnés pour former une \textit{super-action} $\tilde{\mathcal{M}} = \sum_{i=1}^m \tilde{a}_i$
pour laquelle l'environnement retourne une récompense $X_{\tilde{\mathcal{M}}, t}$.
L'objectif demeure la minimisation du pseudo-regret cumulatif \eqref{eq:regret_cumulatif_lineaire}, 
mais celui-ci est désormais calculé entre
la \textit{super-action} optimale $\tilde{\mathcal{M}}^*$ et les \textit{super-actions}
choisies $\tilde{\mathcal{M}}_t$.

\subsection{Représentations vectorielles de phrases}

Les représentations vectorielles utilisées pour les phrases sont basées sur l'observation
que les calculs de ROUGE sont essentiellement basés sur les comptes de \ngrams.
On choisit donc de générer, pour chaque phrase $d_i$ d'un document $d$, un vecteur parcimonieux
représentant le nombre de fois qu'un $n$-gramme donné y est présent.
Pour que les relations entre les phrases soient incorporées dans ces vecteurs,
on associe à chaque $n$-gramme du document un index unique.
On obtient donc, pour chaque phrase, un vecteur parcimonieux $\tilde{d}_i$ de taille $N$,
pour le nombre $N$ de \ngrams dans le document, représentant le 
nombre d'occurrences de chaque $n$-gramme dans la phrase.
Dans nos expériences, on limite l'exploration des \ngrams aux unigrammes,
afin de garder une taille raisonnable pour les vecteurs parcimonieux générés.

On bâtit ensuite une matrice parcimonieuse $P$ dont les rangées sont les vecteurs parcimonieux 
de chaque phrase du document.
La dimension de la matrice $P$ est ensuite réduite via une analyse sémantique latente \citep{10.1145/291128.291131}, 
applicable naturellement dans notre cas de matrice parcimonieuse de grande taille.
Le processus retourne un vecteur de taille $|d|$ pour chaque phrase, que l'on normalise pour avoir 
une norme unitaire et qu'on utilise pour les 
représentations vectorielles $\tilde{a}$.
On note ici que, si aucun $n$-gramme n'était partagé entre les phrases,
leurs représentations vectorielles $\tilde{a}$ seraient
les vecteurs unitaires orthogonaux $e_i$ et, 
comme mentionné à la section \ref{subsec:pr_linucb}, LinUCB serait équivalent à UCB.
Comme pour les scores ROUGE, les vecteurs $\tilde{a}$ associés à un document peuvent 
être pré-calculés pour ne pas avoir à les recalculer inutilement à chaque fois 
que l'on traite un document.

Maintenant que l'on a bien défini le problème de bandit combinatoire linéaire,
regardons comment LinUCB peut être utilisé pour le résoudre à la prochaine section.

\subsection{LinUCB pour bandit combinatoire linéaire}

Tel que décrit à la section \ref{subsec:pr_linucb}, 
Linear Upper Confidence Bound (LinUCB) est une approche permettant 
de minimiser le pseudo-regret cumulatif pour les problèmes de bandit stochastique linéaire.
Pour ce faire, LinUCB maintient des bornes supérieures UCB$_a(t)$ pour chaque action 
$\tilde{a} \in \tilde{\mathcal{A}}$ et chaque pas de temps $t$

\begin{equation}
    \text{UCB}_a(t) = \langle \omega_t^\top, \tilde{a} \rangle +  \beta\sqrt{\tilde{a}^\top \mathbf{V_t}^{-1} \tilde{a}},
    \label{eq:linUCB}
\end{equation}
pour
\begin{equation*}
    \hat{\omega}_t = \mathbf{V_t}^{-1}\mathbf{b_t}, \quad \text{pour} \quad \mathbf{V_t} = \mathbf{I} + \displaystyle \sum_{\tau=1}^t \tilde{a}_{\tau} \tilde{a}_{\tau}^\top, \quad \mathbf{b_t} = \displaystyle \sum_{\tau=1}^t \tilde{a}_{\tau} X_\tau.
\end{equation*}

Ici, $\tilde{a}_\tau$ et $X_\tau$ représentent respectivement l'action prise et 
sa récompense associée perçue au pas de temps numéro $\tau$ alors que $\hat{\omega}_t$
représente la meilleure estimation de $\omega_*$ après $t$ pas de temps.

LinUCB peut encore une fois être étendu au problème de bandit combinatoire.
En effet, il suffit de choisir à chaque pas de temps $t$ la \textit{super-action}
maximisant la borne supérieure définie par UCB sur les actions $\tilde{a} \in \tilde{\mathcal{A}}$.
Dans notre cas, cela revient à sélectionner la \textit{super-action} qui additionne les trois actions
avec la borne supérieure maximale, i.e.

\begin{equation}
    \tilde{\mathcal{M}}_t = \sum_{\tilde{a} \in \mathcal{M}_t} \tilde{a}, \quad\text{pour } \quad \mathcal{M}_t = \text{3-}\argmax_{\tilde{a} \in \tilde{\mathcal{A}}} \text{UCB}_a(t),
    \label{eq:linucb_combi_rule}
\end{equation}

où UCB$_a(t)$ est défini selon \eqref{eq:linUCB}.

La prochaine section décrit le second volet de notre contribution:
l'utilisation de LinUCB pour la génération de cibles extractives 
d'un document. 

\section{Génération de cibles par LinUCB}
\label{sec:cibles_linucb}

La génération de cibles avec LinUCB est presque identique
à celle avec UCB présentée à la section \ref{sec:cibles_ucb}.
Dans notre cas, comme LinUCB ne garantit plus l'exploration de chacune des 
actions, on utilise alors les approximations fournies par $\langle \omega_t, \tilde{a} \rangle$
au lieu des moyennes empiriques $\hat{x}_a$ pour générer les cibles.
Une mise à l'échelle min-max est encore une fois utilisée pour
normaliser les valeurs estimées $\langle \omega_t, \tilde{a} \rangle$.
Cette mise à l'échelle produit des estimés normalisés $x_{\tilde{a}} \in [0, 1]$
en conservant proportions originales entre les moyennes.
Les $x_{\tilde{a}}$ sont ensuite utilisés pour produire les cibles $y_a$ selon

\begin{equation}
    y_a = 10^{-10(1 - x_{\tilde{a}})}.
    \label{eq:cibles_linucb}
\end{equation}

\subsection{Expériences}

Similairement au chapitre sur la formulation combinatoire,
on mesure la sous-optimalité $\Delta_t = R^* - R_t$ des cibles générées
par LinUCB.
On reprend donc notre jeu de développement pour mener des expériences 
sur la qualité des cibles générées par LinUCB.
Le pseudocode utilisé pour les expériences se trouve à l'algorithme 
\ref{alg:cible_linucb}.
Notons que, pour mettre LinUCB à l'échelle de chaque document $d$, 
l'exploration que l'on utilise est plutôt guidée par $\beta' = \frac{\beta}{|d|}$.

\begin{algorithm}
    \setstretch{1.3}
    \caption{LinUCB combinatoire pour génération de résumé}
    \begin{algorithmic}[1]
        \Require $d$ (document), $s$ (résumé cible), $\beta$ (paramètre d'exploration), $T$ (nombre de pas de temps de LinUCB), $\tilde{\mathcal{A}}$ (représentations des phrases).
        \State {$\mathbf{V} = \mathbf{I}$}
        \State {$\mathbf{b} = \mathbf{0}$}
        \For{$t=1, ..., T$}
        \State $\omega_t = \mathbf{V}^{-1}\mathbf{b}$
        \For{$\tilde{a} \in \tilde{\mathcal{A}}$}
        \State UCB$_a = \langle \omega_t^\top, \tilde{a} \rangle + \frac{\beta}{|d|}\sqrt{\tilde{a}^\top \mathbf{V}^{-1} \tilde{a}}$
        \EndFor
        \State $\mathcal{M}_t =$ 3-$\argmax$ UCB$_a$
        \State $X_t = \text{ROUGE}(\mathcal{M}_t, s)$
        \ForAll{$a \in \mathcal{M}_t$}
        \State {$\mathbf{V} = \mathbf{V} + \tilde{a} \tilde{a}^\top$}
        \State {$\mathbf{b} = \mathbf{b} + \tilde{a} X_t $}
        \EndFor
        \EndFor
    \end{algorithmic}
    \label{alg:cible_linucb}
\end{algorithm}


Notre implémentation actuelle diffère légèrement du pseudocode présenté 
en utilisant la nature de la matrice $\mathbf{V}$ pour éviter d'avoir 
à calculer son inverse à chaque ronde et être computationnellement plus efficace.
Les détails techniques de cette manipulation sont disponibles dans l'annexe 
\ref{chap:lincub_gains} pour le lecteur intéressé.

\subsection{Résultats}

Les résultats obtenus sont présentés dans les figures 
\ref{fig:bandit_combi_lin_alpha} et \ref{fig:bandit_combi_lin_doc_len}.
Il est à noter que les différences rapportées entre les différentes 
courbes sur les figures ne sont pas statistiquement significatives.
Pour éviter d'encombrer inutilement les figures, on rapporte alors 
seulement les moyennes observées.
Les versions incorporant la déviation standard des différentes courbes 
se trouvent à l'annexe \ref{chap:variance_graphs}.

La figure \ref{fig:bandit_combi_lin_alpha} présente comment l'hyperparamètre $\beta$ influence la
convergence de LinUCB.
On remarque d'abord que, comme il fallait s'y attendre, LinUCB converge
nettement plus rapidement à des cibles de bonne qualité que UCB.
En effet, l'erreur $\Delta_t$ de près 0.05 observée avec UCB après 250 pas de temps est plutôt 
observable après 50 pas de temps de LinUCB.
On remarque aussi que $\beta=10^8$ (courbe bleue sur la figure) semble être un bon choix,
réussissant à converger légèrement plus rapidement que $\beta=10^7$.

\tikzsetnextfilename{bandit_combi_lin_alpha}
\begin{figure}[h!]
    \begin{center}
        \begin{tikzpicture}
            \begin{axis}[title={Impact de l'exploration sur la progression de la sous-optimalité}, grid style={dashed,gray!50}, axis y line*=left, axis x line*=bottom, every axis plot/.append style={line width=1.5pt, mark size=0pt, font=\huge}, name=plot0, y tick label style={/pgf/number format/fixed zerofill}, ylabel={$\Delta_t$}, xlabel={$t$}, width=0.95\textwidth, height=0.4\textwidth, smooth, xmin=0, xmax=100, y tick label style={/pgf/number format/fixed}, ytick={0.00, 0.05, 0.10, 0.15, 0.20, 0.25}]
                \addplot[red, ylabel near ticks, line width=3pt] table[x=t, y=1000000_, col sep=comma]{bandit_combi_lin/bandit_combi_linExpResults/alpha/all.csv};
                \addplot[green, ylabel near ticks, line width=3pt] table[x=t, y=10000000.0_, col sep=comma]{bandit_combi_lin/bandit_combi_linExpResults/alpha/all.csv};
                \addplot[blue, ylabel near ticks, line width=3pt] table[x=t, y=100000000.0_, col sep=comma]{bandit_combi_lin/bandit_combi_linExpResults/alpha/all.csv};
                \addplot[black, ylabel near ticks, line width=3pt] table[x=t, y=q_1e1, col sep=comma]{bandit_combi/bandit_combiExpResults/alpha/all.csv};
                \legend{$\beta=10^6$, $\beta = 10^7$, $\beta = 10^8$, UCB}
            \end{axis}
        \end{tikzpicture}
    \end{center}
    \caption{Impact du paramètre d'exploration $\beta$ utilisé par LinUCB sur la convergence.
    $\Delta_t$ représente la différence entre le score ROUGE du meilleur résumé selon LinUCB et 
    celui généré par l'oracle.}
    \label{fig:bandit_combi_lin_alpha}
\end{figure}

La figure \ref{fig:bandit_combi_lin_doc_len} évalue dans quelle mesure la taille des documents
influe sur la sous-optimalité des cibles générées par UCB.
La valeur $\beta=10^8$ (courbe bleue) semble encore une fois optimale et ce, pour toutes les tailles 
de document.
Similairement à ce qui avait été observé pour les cibles générées par UCB, il semble que de 
rouler LinUCB avec plus de pas de temps est bénéfique pour les documents plus longs.

\begin{figure}[h!]
    \tikzsetnextfilename{bandit_combi_lin_less20}
    \begin{tikzpicture}[baseline]
        \begin{axis}[grid style={dashed,gray!50}, axis y line*=left, axis x line*=bottom, every axis plot/.append style={line width=1.5pt, mark size=0pt, font=\Large}, width=0.34\textwidth,
                height=0.4\textwidth, name=plot0, y tick label style={/pgf/number format/fixed zerofill}, xmin=0.0, xmax=100.0, ymin=0.01, ymax=0.30, ylabel={$\Delta_t$}, xlabel={$t$}, smooth, title={$|d| \leq 20$}]
            \addplot[red, ylabel near ticks, line width=3pt] table[x=t, y=less20_1000000_, col sep=comma]{bandit_combi_lin/bandit_combi_linExpResults/doc_len/all.csv};
            \addplot[green, ylabel near ticks, line width=3pt] table[x=t, y=less20_10000000.0_, col sep=comma]{bandit_combi_lin/bandit_combi_linExpResults/doc_len/all.csv};
            \addplot[blue, ylabel near ticks, line width=3pt] table[x=t, y=less20_100000000.0_, col sep=comma]{bandit_combi_lin/bandit_combi_linExpResults/doc_len/all.csv};
            \legend{$\beta=10^6$, $\beta = 10^7$, $\beta = 10^8$}
        \end{axis}
    \end{tikzpicture}
    \tikzsetnextfilename{bandit_combi_lin_20to35}
    \begin{tikzpicture}[baseline]
        \begin{axis}[grid style={dashed,gray!50}, axis y line*=left, axis x line*=bottom, every axis plot/.append style={line width=1.5pt, mark size=0pt, font=\huge}, width=.34\textwidth,
                height=0.4\textwidth, name=plot0, xshift=-.1\textwidth, y tick label style={/pgf/number format/fixed zerofill},xmin=0.0, xmax=100.0, ymin=0.01, ymax=0.30, xlabel={$t$}, legend style={at={(0.9,0.1)},anchor=south east}, smooth, title={$20 < |d| < 35$}, ymajorticks=false]
            \addplot[red, ylabel near ticks, line width=3pt] table[x=t, y=20to35_1000000_, col sep=comma]{bandit_combi_lin/bandit_combi_linExpResults/doc_len/all.csv};
            \addplot[green, ylabel near ticks, line width=3pt] table[x=t, y=20to35_10000000.0_, col sep=comma]{bandit_combi_lin/bandit_combi_linExpResults/doc_len/all.csv};
            \addplot[blue, ylabel near ticks, line width=3pt] table[x=t, y=20to35_100000000.0_, col sep=comma]{bandit_combi_lin/bandit_combi_linExpResults/doc_len/all.csv};
        \end{axis}
    \end{tikzpicture}
    \tikzsetnextfilename{bandit_combi_lin_more35}
    \begin{tikzpicture}[baseline]
        \begin{axis}[grid style={dashed,gray!50}, axis y line*=right, axis x line*=bottom, every axis plot/.append style={line width=1.5pt, mark size=0pt, font=\huge}, width=.34\textwidth,
                height=0.4\textwidth, name=plot0, xshift=-.1\textwidth, y tick label style={/pgf/number format/fixed zerofill}, xmin=0.0, xmax=100.0, ymin=0.01, ymax=0.30, xlabel={$t$}, legend style={at={(1,0.1)},anchor=south east}, smooth, title={$35 \leq |d|$}]
            \addplot[red, ylabel near ticks, line width=3pt] table[x=t, y=more35_1000000_, col sep=comma]{bandit_combi_lin/bandit_combi_linExpResults/doc_len/all.csv};
            \addplot[green, ylabel near ticks, line width=3pt] table[x=t, y=more35_10000000.0_, col sep=comma]{bandit_combi_lin/bandit_combi_linExpResults/doc_len/all.csv};
            \addplot[blue, ylabel near ticks, line width=3pt] table[x=t, y=more35_100000000.0_, col sep=comma]{bandit_combi_lin/bandit_combi_linExpResults/doc_len/all.csv};
        \end{axis}
    \end{tikzpicture}
    \caption{Impact de la taille du document sur la convergence de LinUCB.
    $\Delta_t$ représente la différence entre le score ROUGE du meilleur résumé selon UCB et 
    celui généré par l'oracle.}
    \label{fig:bandit_combi_lin_doc_len}
\end{figure}

\section{LinCombiSum}
\label{section:lincombisum}

On propose maintenant un système de génération de résumés complet nommé LinCombiSum,
qui se veut identique à CombiSum (\ref{sec:combisum}) mais qui utilise LinUCB
au lieu de UCB pour générer ses cibles selon l'équation \ref{eq:cibles_linucb}.
Conformément aux méthodes de l'état de l'art sur l'apprentissage 
de cibles \citep{liu2019text}, la mise à jour des paramètres est faite selon la 
perte basée sur l'entropie croisée binaire entre une cible $y$
et un vecteur d'affinités produit $\hat{y} = \pi_\theta(d)$:

\begin{equation}
    l(\hat{y}, y) = \frac{1}{|y|} \sum_{i=1}^{|y|}\big[y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i) \big].
    \label{eq:bce_linucb}
\end{equation}

En se basant sur les résultats de la section précédente, on explore deux 
fonctions $T(d)$ déterminant le nombre $T$ de pas de temps utilisés pour 
générer les cibles UCB pour un document $d$.
Premièrement, on considère une version fixe $T_f(d)=50$, correspondant à une 
bonne estimation pour toutes les tailles de document.
On considère aussi une version $T_l(d)=|d| + 25$ augmentant linéairement selon 
le nombre de phrases d'un document.
Comme notre régularisation limite les documents à 50 phrases ou moins, 
$T_l(d)$ varie entre 25 et 75, avec une moyenne (sur les tailles de document) à 
50.
Ainsi, $T_f$ et $T_l$ utiliseront le même nombre de pas de temps en moyenne 
et il sera possible de valider laquelle des deux fonctions permet 
le meilleur entraînement.

\subsection{Expériences}

Une description détaillée de LinCombiSum est fournie à l'algorithme \ref{alg:systeme_linucb}.
On effectue un entraînement sur le jeu de données CNN/DailyMail en 
parcourant dans son entièreté le jeu de d'entraînement à 5 reprises
et en utilisant des \textit{minibatches} de taille $B=64$.
Notre implémentation est faite selon les détails expérimentaux décrits à la section 
\ref{subsec:archi}.

\begin{algorithm}
    \setstretch{1.3}
    \caption{LinCombiSum}
    \begin{algorithmic}[1]
        \Require  $\mathcal{D}$ (jeu de données), $T$ (fonction pour le nombre de pas de temps), $\alpha$ (taux d'apprentissage), $\beta$ (taux d'exploration UCB), $B$ (taille de minibatch).
        \While{vrai}
        \State{batch $\sim \mathcal{D}^B$} \Comment{On pige la minibatch du jeu de données}
        \State $\nabla = \mathbf{0}$
        \ForAll{$(d,s) \in $ batch}
        \State $\hat{y} = \pi_\theta(d)$
        \State Obtenir les représentations $\tilde{a}$ des phrases de $d$
        \State Exécuter $T(d)$ pas de temps de UCB et obtenir $\langle \hat{\omega}_T, \tilde{a}_i \rangle$
        \State Générer les cibles $y$ à partir de $\langle \hat{\omega}_T, \tilde{a}_i \rangle$ \Comment{Selon \eqref{eq:cibles_linucb}}
        \State $\nabla = \nabla + \nabla_\theta l(\hat{y}, y)$\Comment{Selon \eqref{eq:bce_linucb}}
        \EndFor
        \State $\theta = \theta - \alpha \nabla$
        \EndWhile
    \end{algorithmic}
    \label{alg:systeme_linucb}
\end{algorithm}

Pour les expériences, on s'intéresse à
l'impact de la fonction $T$ utilisée.
On expérimente donc avec $T = T_f$ et $T=T_l$,
tel que décrits plus haut.
En guise de référence, on entraîne aussi un modèle 
en utilisant les cibles binaire générées par l'oracle telles que décrites
à la section \ref{sec:cibles_ucb}.
Étant donné le facteur aléatoire présent dans l'entraînement, nous effectuons 
5 entraînements distincts pour chaque $T$ et présentons la moyenne
des résultats obtenus.

\subsection{Résultats}

Les résultats obtenus sont présentés dans la figure \ref{fig:lcs_learning_curve} 
et le tableau \ref{tab:ROUGE_LINUCB}.
Ici, UCB linéaire et fixe font référence respectivement à l'utilisation
à l'utilisation $T_l$ et $T_f$ pour déterminer le nombre de pas de temps
effectués par UCB.

Tout d'abord, la figure \ref{fig:lcs_learning_curve} illustre l'évolution 
de la performance sur le jeu de validation des modèles selon 
les cibles utilisées.
On constate d'abord que la performance en validation avec les cibles 
UCB atteint rapidement un plateau à partir duquel elle 
ne varie plus.
Ce plateau n'affecte toutefois pas l'entraînement avec les cibles binaires,
avec lesquelles l'apprentissage continue de varier jusqu'à
éventuellement dépasser légèrement la performance des cibles LinUCB.

\tikzsetnextfilename{lincombisum_learning_curve}
\begin{figure}[h!]
    \begin{center}
        \begin{tikzpicture}
            \begin{axis}[title={Performance sur le jeu de validation selon la cible utilisée}, grid style={dashed,gray!50}, axis y line*=left, axis x line*=bottom, every axis plot/.append style={line width=1.5pt, mark size=0pt, font=\huge}, name=plot0, y tick label style={/pgf/number format/fixed zerofill}, ylabel={ROUGE}, xlabel={Nombre de mises à jour (en milliers)}, width=0.95\textwidth, height=0.4\textwidth, smooth, xmin=0.5, legend style={at={(0.9,0.1)},anchor=south east}, legend cell align={left}, xmax=22.5, y tick label style={/pgf/number format/fixed}]
                \addplot[blue, ylabel near ticks, line width=2pt] table[x=t, y=linsit_fix, col sep=comma]{bandit_combi/graham_results/cs_learning_curve.csv};
                \addplot[forget plot, name path=upperblue, draw=none] table[x=t, y=linsit_fix_+, col sep=comma]{bandit_combi/graham_results/cs_learning_curve.csv};
                \addplot[forget plot, name path=lowerblue, draw=none] table[x=t, y=linsit_fix_-, col sep=comma]{bandit_combi/graham_results/cs_learning_curve.csv};
                \addplot[red, ylabel near ticks, line width=2pt] table[x=t, y=linsit_linear, col sep=comma]{bandit_combi/graham_results/cs_learning_curve.csv};
                \addplot[forget plot, name path=upperred, draw=none] table[x=t, y=linsit_linear_+, col sep=comma]{bandit_combi/graham_results/cs_learning_curve.csv};
                \addplot[forget plot, name path=lowerred, draw=none] table[x=t, y=linsit_linear_-, col sep=comma]{bandit_combi/graham_results/cs_learning_curve.csv};
                \addplot[green, ylabel near ticks, line width=2pt] table[x=t, y=binary_linear, col sep=comma]{bandit_combi/graham_results/cs_learning_curve.csv};
                \addplot[forget plot, name path=uppergreen, draw=none] table[x=t, y=binary_linear_+, col sep=comma]{bandit_combi/graham_results/cs_learning_curve.csv};
                \addplot[forget plot, name path=lowergreen, draw=none] table[x=t, y=binary_linear_-, col sep=comma]{bandit_combi/graham_results/cs_learning_curve.csv};
                \addplot[fill=blue!20, fill opacity=0.5] fill between[of=upperblue and lowerblue];
                \addplot[fill=red!20, fill opacity=0.5] fill between[of=upperred and lowerred];
                \addplot[fill=green!20, fill opacity=0.5] fill between[of=uppergreen and lowergreen];
                \legend{LinUCB fixe, LinUCB linéaire, Oracle}
            \end{axis}
        \end{tikzpicture}
    \end{center}
    \caption{Courbe d'apprentissage de LinCombiSum selon la cible utilisée.
             Un intervalle de confiance à 95 \% calculé à partir de 5 entraînements distincts
             est rapporté pour chaque cible.}
    \label{fig:lcs_learning_curve}
\end{figure}

Le tableau \ref{tab:ROUGE_LINUCB} présente la performance 
obtenue par nos modèles et par la référence Lead-3 sur le jeu de test.
Pour chaque entraînement effectué, la performance en test 
rapportée est celle obtenue avec les paramètres $\theta$
permettant d'obtenir la meilleure performance en validation.

\begin{table}[!h]
    \centering
    \def\arraystretch{1.8}
    \resizebox{0.8\textwidth}{!}{%
    \begin{tabular}{ccccc}
    \specialrule{.2em}{.1em}{.1em}
    \multicolumn{1}{c}{\textbf{Cible utilisée}} & \multicolumn{1}{c}{\textbf{ROUGE-1}} & \multicolumn{1}{c}{\textbf{ROUGE-2}} & \multicolumn{1}{c}{\textbf{ROUGE-L}} & \multicolumn{1}{c}{\textbf{ROUGE}} \\ \specialrule{.2em}{.1em}{.1em}
    Lead-3 & 39.59  & 17.68 & 36.21 & 31.16\\ \specialrule{.1em}{.05em}{.05em}
    LinUCB fixe & $39.91 \pm 0.04$  & $\mathbf{18.11 \pm 0.05}$  & $36.33 \pm 0.06$ & $31.45 \pm 0.05$\\
    LinUCB linéaire & $39.84 \pm 0.06$  & $\mathbf{18.03 \pm 0.04}$ & $36.25 \pm 0.06$ & $31.37 \pm 0.06$ \\ 
    Oracle & $\mathbf{40.47 \pm 0.27}$ & $\mathbf{18.21 \pm 0.15}$ & $\mathbf{36.93 \pm 0.24}$ & $\mathbf{31.87 \pm 0.22}$ \\\specialrule{.2em}{.1em}{.1em}
    \end{tabular}
    }
    \caption{Performance sur le jeu de test.}
    \label{tab:ROUGE_LINUCB}
\end{table}

Un premier constat qui se pose est que, peu importe la cible 
utilisée, les modèles produits se comportent de manière 
extrêmement similaire sur le jeu de test.
Aussi, la performance obtenue n'est que 
très légèrement supérieure à Lead-3.

En somme, les résultats obtenus par LinCombiSum sont décevants,
ne se distinguant que très légèrement de la référence Lead-3.
Nous élaborons davantage sur les potentielles 
justifications de cette performance et discutons 
d'une piste de solution envisageable au chapitre \ref{chap:analyse_convergemce}.

\section{Conclusion}

Dans ce chapitre, nous avons proposé de nouvelles cibles plus riches
pour l'entraînement d'un modèle de génération de résumés.
Nos nouvelles cibles sont basées sur une version 
de LinUCB adaptée au bandit combinatoire, dont nous avons validé 
l'applicabilité sur notre jeu de développement.
Enfin, nous avons présenté comment les cibles 
peuvent être utilisées dans un algorithme 
que nous avons nommé CombiSum.

Dans le prochain chapitre, on compare 
de manière exhaustive les cibles 
générées par UCB et LinUCB ainsi que les modèles 
qu'elles génèrent.